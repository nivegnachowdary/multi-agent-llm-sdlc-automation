{
  "best_metric": 0.32043060660362244,
  "best_model_checkpoint": "./codellama_finetuned/checkpoint-13000",
  "epoch": 2.9975786924939465,
  "eval_steps": 500,
  "global_step": 13000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023060071486221606,
      "grad_norm": 8.638057708740234,
      "learning_rate": 3.88e-06,
      "loss": 3.4773,
      "step": 100
    },
    {
      "epoch": 0.04612014297244321,
      "grad_norm": 0.3764396011829376,
      "learning_rate": 7.88e-06,
      "loss": 0.955,
      "step": 200
    },
    {
      "epoch": 0.06918021445866482,
      "grad_norm": 1.327634572982788,
      "learning_rate": 1.188e-05,
      "loss": 0.632,
      "step": 300
    },
    {
      "epoch": 0.09224028594488642,
      "grad_norm": 0.47669363021850586,
      "learning_rate": 1.588e-05,
      "loss": 0.5415,
      "step": 400
    },
    {
      "epoch": 0.11530035743110803,
      "grad_norm": 1.0128928422927856,
      "learning_rate": 1.9880000000000003e-05,
      "loss": 0.4858,
      "step": 500
    },
    {
      "epoch": 0.11530035743110803,
      "eval_loss": 0.4637836813926697,
      "eval_runtime": 739.8079,
      "eval_samples_per_second": 10.422,
      "eval_steps_per_second": 2.606,
      "step": 500
    },
    {
      "epoch": 0.13836042891732964,
      "grad_norm": 1.727565050125122,
      "learning_rate": 1.984489926447074e-05,
      "loss": 0.4437,
      "step": 600
    },
    {
      "epoch": 0.16142050040355124,
      "grad_norm": 0.7618432641029358,
      "learning_rate": 1.9685001598976657e-05,
      "loss": 0.434,
      "step": 700
    },
    {
      "epoch": 0.18448057188977285,
      "grad_norm": 0.4151262044906616,
      "learning_rate": 1.9525103933482572e-05,
      "loss": 0.3984,
      "step": 800
    },
    {
      "epoch": 0.20754064337599445,
      "grad_norm": 0.6906503438949585,
      "learning_rate": 1.936520626798849e-05,
      "loss": 0.3881,
      "step": 900
    },
    {
      "epoch": 0.23060071486221606,
      "grad_norm": 0.8690191507339478,
      "learning_rate": 1.9205308602494406e-05,
      "loss": 0.3741,
      "step": 1000
    },
    {
      "epoch": 0.23060071486221606,
      "eval_loss": 0.3710733652114868,
      "eval_runtime": 737.2351,
      "eval_samples_per_second": 10.458,
      "eval_steps_per_second": 2.615,
      "step": 1000
    },
    {
      "epoch": 0.2536607863484377,
      "grad_norm": 0.4339626729488373,
      "learning_rate": 1.904541093700032e-05,
      "loss": 0.3541,
      "step": 1100
    },
    {
      "epoch": 0.2767208578346593,
      "grad_norm": 0.3472363352775574,
      "learning_rate": 1.8885513271506236e-05,
      "loss": 0.3712,
      "step": 1200
    },
    {
      "epoch": 0.2997809293208809,
      "grad_norm": 0.44881880283355713,
      "learning_rate": 1.872561560601215e-05,
      "loss": 0.3556,
      "step": 1300
    },
    {
      "epoch": 0.3228410008071025,
      "grad_norm": 0.3176758587360382,
      "learning_rate": 1.856571794051807e-05,
      "loss": 0.3676,
      "step": 1400
    },
    {
      "epoch": 0.3459010722933241,
      "grad_norm": 0.36354726552963257,
      "learning_rate": 1.8405820275023985e-05,
      "loss": 0.3608,
      "step": 1500
    },
    {
      "epoch": 0.3459010722933241,
      "eval_loss": 0.35650721192359924,
      "eval_runtime": 737.2838,
      "eval_samples_per_second": 10.457,
      "eval_steps_per_second": 2.615,
      "step": 1500
    },
    {
      "epoch": 0.3689611437795457,
      "grad_norm": 0.30828049778938293,
      "learning_rate": 1.8245922609529904e-05,
      "loss": 0.3528,
      "step": 1600
    },
    {
      "epoch": 0.39202121526576733,
      "grad_norm": 0.35464048385620117,
      "learning_rate": 1.808602494403582e-05,
      "loss": 0.3491,
      "step": 1700
    },
    {
      "epoch": 0.4150812867519889,
      "grad_norm": 0.49222278594970703,
      "learning_rate": 1.7926127278541735e-05,
      "loss": 0.3394,
      "step": 1800
    },
    {
      "epoch": 0.43814135823821054,
      "grad_norm": 0.33457833528518677,
      "learning_rate": 1.7766229613047653e-05,
      "loss": 0.3472,
      "step": 1900
    },
    {
      "epoch": 0.4612014297244321,
      "grad_norm": 0.32505539059638977,
      "learning_rate": 1.760633194755357e-05,
      "loss": 0.3378,
      "step": 2000
    },
    {
      "epoch": 0.4612014297244321,
      "eval_loss": 0.3492445945739746,
      "eval_runtime": 737.0026,
      "eval_samples_per_second": 10.461,
      "eval_steps_per_second": 2.616,
      "step": 2000
    },
    {
      "epoch": 0.48426150121065376,
      "grad_norm": 0.34139829874038696,
      "learning_rate": 1.7446434282059484e-05,
      "loss": 0.3509,
      "step": 2100
    },
    {
      "epoch": 0.5073215726968754,
      "grad_norm": 0.3709012269973755,
      "learning_rate": 1.72865366165654e-05,
      "loss": 0.3363,
      "step": 2200
    },
    {
      "epoch": 0.530381644183097,
      "grad_norm": 0.3751715123653412,
      "learning_rate": 1.7126638951071314e-05,
      "loss": 0.3435,
      "step": 2300
    },
    {
      "epoch": 0.5534417156693185,
      "grad_norm": 0.3281788229942322,
      "learning_rate": 1.6966741285577233e-05,
      "loss": 0.3413,
      "step": 2400
    },
    {
      "epoch": 0.5765017871555402,
      "grad_norm": 0.331220418214798,
      "learning_rate": 1.6806843620083148e-05,
      "loss": 0.3394,
      "step": 2500
    },
    {
      "epoch": 0.5765017871555402,
      "eval_loss": 0.34381183981895447,
      "eval_runtime": 737.0174,
      "eval_samples_per_second": 10.461,
      "eval_steps_per_second": 2.616,
      "step": 2500
    },
    {
      "epoch": 0.5995618586417618,
      "grad_norm": 0.3340955078601837,
      "learning_rate": 1.6646945954589063e-05,
      "loss": 0.3466,
      "step": 2600
    },
    {
      "epoch": 0.6226219301279834,
      "grad_norm": 0.29742559790611267,
      "learning_rate": 1.648704828909498e-05,
      "loss": 0.3392,
      "step": 2700
    },
    {
      "epoch": 0.645682001614205,
      "grad_norm": 0.3656415343284607,
      "learning_rate": 1.6327150623600897e-05,
      "loss": 0.3381,
      "step": 2800
    },
    {
      "epoch": 0.6687420731004267,
      "grad_norm": 0.3852033019065857,
      "learning_rate": 1.6167252958106813e-05,
      "loss": 0.3297,
      "step": 2900
    },
    {
      "epoch": 0.6918021445866482,
      "grad_norm": 0.3754521310329437,
      "learning_rate": 1.600735529261273e-05,
      "loss": 0.3382,
      "step": 3000
    },
    {
      "epoch": 0.6918021445866482,
      "eval_loss": 0.3403494358062744,
      "eval_runtime": 737.0651,
      "eval_samples_per_second": 10.46,
      "eval_steps_per_second": 2.616,
      "step": 3000
    },
    {
      "epoch": 0.7148622160728698,
      "grad_norm": 0.3115736246109009,
      "learning_rate": 1.5847457627118646e-05,
      "loss": 0.3329,
      "step": 3100
    },
    {
      "epoch": 0.7379222875590914,
      "grad_norm": 0.34928473830223083,
      "learning_rate": 1.5687559961624562e-05,
      "loss": 0.3268,
      "step": 3200
    },
    {
      "epoch": 0.7609823590453131,
      "grad_norm": 0.28575512766838074,
      "learning_rate": 1.5527662296130477e-05,
      "loss": 0.3351,
      "step": 3300
    },
    {
      "epoch": 0.7840424305315347,
      "grad_norm": 0.31926682591438293,
      "learning_rate": 1.5367764630636396e-05,
      "loss": 0.3342,
      "step": 3400
    },
    {
      "epoch": 0.8071025020177562,
      "grad_norm": 0.371233731508255,
      "learning_rate": 1.5207866965142311e-05,
      "loss": 0.3286,
      "step": 3500
    },
    {
      "epoch": 0.8071025020177562,
      "eval_loss": 0.3369659185409546,
      "eval_runtime": 736.9707,
      "eval_samples_per_second": 10.462,
      "eval_steps_per_second": 2.616,
      "step": 3500
    },
    {
      "epoch": 0.8301625735039778,
      "grad_norm": 0.35994723439216614,
      "learning_rate": 1.5047969299648226e-05,
      "loss": 0.3215,
      "step": 3600
    },
    {
      "epoch": 0.8532226449901995,
      "grad_norm": 0.34125328063964844,
      "learning_rate": 1.4888071634154141e-05,
      "loss": 0.3254,
      "step": 3700
    },
    {
      "epoch": 0.8762827164764211,
      "grad_norm": 0.3442603647708893,
      "learning_rate": 1.4728173968660058e-05,
      "loss": 0.3319,
      "step": 3800
    },
    {
      "epoch": 0.8993427879626427,
      "grad_norm": 0.31472229957580566,
      "learning_rate": 1.4568276303165975e-05,
      "loss": 0.329,
      "step": 3900
    },
    {
      "epoch": 0.9224028594488642,
      "grad_norm": 0.3359174430370331,
      "learning_rate": 1.4408378637671892e-05,
      "loss": 0.3303,
      "step": 4000
    },
    {
      "epoch": 0.9224028594488642,
      "eval_loss": 0.334585964679718,
      "eval_runtime": 737.0728,
      "eval_samples_per_second": 10.46,
      "eval_steps_per_second": 2.616,
      "step": 4000
    },
    {
      "epoch": 0.9454629309350859,
      "grad_norm": 0.3532699942588806,
      "learning_rate": 1.4248480972177808e-05,
      "loss": 0.3277,
      "step": 4100
    },
    {
      "epoch": 0.9685230024213075,
      "grad_norm": 0.33548739552497864,
      "learning_rate": 1.4088583306683723e-05,
      "loss": 0.3321,
      "step": 4200
    },
    {
      "epoch": 0.9915830739075291,
      "grad_norm": 0.359286904335022,
      "learning_rate": 1.3928685641189638e-05,
      "loss": 0.3257,
      "step": 4300
    },
    {
      "epoch": 1.0145278450363195,
      "grad_norm": 0.37324631214141846,
      "learning_rate": 1.3768787975695557e-05,
      "loss": 0.3254,
      "step": 4400
    },
    {
      "epoch": 1.0375879165225412,
      "grad_norm": 0.40104806423187256,
      "learning_rate": 1.3608890310201472e-05,
      "loss": 0.3157,
      "step": 4500
    },
    {
      "epoch": 1.0375879165225412,
      "eval_loss": 0.3327549397945404,
      "eval_runtime": 736.9389,
      "eval_samples_per_second": 10.462,
      "eval_steps_per_second": 2.616,
      "step": 4500
    },
    {
      "epoch": 1.060647988008763,
      "grad_norm": 0.3158746361732483,
      "learning_rate": 1.3448992644707389e-05,
      "loss": 0.3316,
      "step": 4600
    },
    {
      "epoch": 1.0837080594949844,
      "grad_norm": 0.36762329936027527,
      "learning_rate": 1.3289094979213304e-05,
      "loss": 0.3254,
      "step": 4700
    },
    {
      "epoch": 1.106768130981206,
      "grad_norm": 0.3776393532752991,
      "learning_rate": 1.312919731371922e-05,
      "loss": 0.3272,
      "step": 4800
    },
    {
      "epoch": 1.1298282024674275,
      "grad_norm": 0.3509727120399475,
      "learning_rate": 1.2969299648225138e-05,
      "loss": 0.3295,
      "step": 4900
    },
    {
      "epoch": 1.1528882739536492,
      "grad_norm": 0.3703526556491852,
      "learning_rate": 1.2809401982731053e-05,
      "loss": 0.328,
      "step": 5000
    },
    {
      "epoch": 1.1528882739536492,
      "eval_loss": 0.33090507984161377,
      "eval_runtime": 737.165,
      "eval_samples_per_second": 10.459,
      "eval_steps_per_second": 2.615,
      "step": 5000
    },
    {
      "epoch": 1.175948345439871,
      "grad_norm": 0.3667949438095093,
      "learning_rate": 1.2649504317236969e-05,
      "loss": 0.3182,
      "step": 5100
    },
    {
      "epoch": 1.1990084169260924,
      "grad_norm": 0.3605756461620331,
      "learning_rate": 1.2489606651742885e-05,
      "loss": 0.3212,
      "step": 5200
    },
    {
      "epoch": 1.222068488412314,
      "grad_norm": 0.37785354256629944,
      "learning_rate": 1.2329708986248802e-05,
      "loss": 0.3244,
      "step": 5300
    },
    {
      "epoch": 1.2451285598985358,
      "grad_norm": 0.3810139298439026,
      "learning_rate": 1.216981132075472e-05,
      "loss": 0.3283,
      "step": 5400
    },
    {
      "epoch": 1.2681886313847572,
      "grad_norm": 0.37808167934417725,
      "learning_rate": 1.2009913655260635e-05,
      "loss": 0.3133,
      "step": 5500
    },
    {
      "epoch": 1.2681886313847572,
      "eval_loss": 0.329548180103302,
      "eval_runtime": 736.9457,
      "eval_samples_per_second": 10.462,
      "eval_steps_per_second": 2.616,
      "step": 5500
    },
    {
      "epoch": 1.291248702870979,
      "grad_norm": 0.34836724400520325,
      "learning_rate": 1.185001598976655e-05,
      "loss": 0.3219,
      "step": 5600
    },
    {
      "epoch": 1.3143087743572006,
      "grad_norm": 0.3832583725452423,
      "learning_rate": 1.1690118324272465e-05,
      "loss": 0.3256,
      "step": 5700
    },
    {
      "epoch": 1.337368845843422,
      "grad_norm": 0.3729880452156067,
      "learning_rate": 1.1530220658778384e-05,
      "loss": 0.3246,
      "step": 5800
    },
    {
      "epoch": 1.3604289173296438,
      "grad_norm": 0.36557537317276,
      "learning_rate": 1.1370322993284299e-05,
      "loss": 0.317,
      "step": 5900
    },
    {
      "epoch": 1.3834889888158655,
      "grad_norm": 0.42294028401374817,
      "learning_rate": 1.1210425327790216e-05,
      "loss": 0.3245,
      "step": 6000
    },
    {
      "epoch": 1.3834889888158655,
      "eval_loss": 0.3282617926597595,
      "eval_runtime": 737.211,
      "eval_samples_per_second": 10.458,
      "eval_steps_per_second": 2.615,
      "step": 6000
    },
    {
      "epoch": 1.406549060302087,
      "grad_norm": 0.3448981046676636,
      "learning_rate": 1.1050527662296131e-05,
      "loss": 0.3228,
      "step": 6100
    },
    {
      "epoch": 1.4296091317883086,
      "grad_norm": 0.3819884657859802,
      "learning_rate": 1.0890629996802047e-05,
      "loss": 0.3254,
      "step": 6200
    },
    {
      "epoch": 1.45266920327453,
      "grad_norm": 0.3452933430671692,
      "learning_rate": 1.0730732331307965e-05,
      "loss": 0.3247,
      "step": 6300
    },
    {
      "epoch": 1.4757292747607518,
      "grad_norm": 0.37685897946357727,
      "learning_rate": 1.057083466581388e-05,
      "loss": 0.3279,
      "step": 6400
    },
    {
      "epoch": 1.4987893462469732,
      "grad_norm": 0.3524670898914337,
      "learning_rate": 1.0410937000319796e-05,
      "loss": 0.3206,
      "step": 6500
    },
    {
      "epoch": 1.4987893462469732,
      "eval_loss": 0.3268578052520752,
      "eval_runtime": 736.9943,
      "eval_samples_per_second": 10.461,
      "eval_steps_per_second": 2.616,
      "step": 6500
    },
    {
      "epoch": 1.521849417733195,
      "grad_norm": 0.3940987288951874,
      "learning_rate": 1.0251039334825713e-05,
      "loss": 0.3198,
      "step": 6600
    },
    {
      "epoch": 1.5449094892194166,
      "grad_norm": 0.40694355964660645,
      "learning_rate": 1.0091141669331628e-05,
      "loss": 0.3237,
      "step": 6700
    },
    {
      "epoch": 1.567969560705638,
      "grad_norm": 0.3953476548194885,
      "learning_rate": 9.931244003837545e-06,
      "loss": 0.3198,
      "step": 6800
    },
    {
      "epoch": 1.5910296321918598,
      "grad_norm": 0.37051844596862793,
      "learning_rate": 9.771346338343462e-06,
      "loss": 0.316,
      "step": 6900
    },
    {
      "epoch": 1.6140897036780815,
      "grad_norm": 0.3140556514263153,
      "learning_rate": 9.611448672849377e-06,
      "loss": 0.3139,
      "step": 7000
    },
    {
      "epoch": 1.6140897036780815,
      "eval_loss": 0.32613062858581543,
      "eval_runtime": 737.0427,
      "eval_samples_per_second": 10.461,
      "eval_steps_per_second": 2.616,
      "step": 7000
    },
    {
      "epoch": 1.637149775164303,
      "grad_norm": 0.37038472294807434,
      "learning_rate": 9.451551007355292e-06,
      "loss": 0.3121,
      "step": 7100
    },
    {
      "epoch": 1.6602098466505246,
      "grad_norm": 0.40475255250930786,
      "learning_rate": 9.29165334186121e-06,
      "loss": 0.3203,
      "step": 7200
    },
    {
      "epoch": 1.6832699181367463,
      "grad_norm": 0.42121049761772156,
      "learning_rate": 9.131755676367126e-06,
      "loss": 0.3294,
      "step": 7300
    },
    {
      "epoch": 1.7063299896229678,
      "grad_norm": 0.3453580141067505,
      "learning_rate": 8.971858010873043e-06,
      "loss": 0.3254,
      "step": 7400
    },
    {
      "epoch": 1.7293900611091895,
      "grad_norm": 0.368234246969223,
      "learning_rate": 8.811960345378958e-06,
      "loss": 0.3157,
      "step": 7500
    },
    {
      "epoch": 1.7293900611091895,
      "eval_loss": 0.32520827651023865,
      "eval_runtime": 737.0526,
      "eval_samples_per_second": 10.461,
      "eval_steps_per_second": 2.616,
      "step": 7500
    },
    {
      "epoch": 1.7524501325954112,
      "grad_norm": 0.3931369185447693,
      "learning_rate": 8.652062679884874e-06,
      "loss": 0.3216,
      "step": 7600
    },
    {
      "epoch": 1.7755102040816326,
      "grad_norm": 0.3670767545700073,
      "learning_rate": 8.49216501439079e-06,
      "loss": 0.3168,
      "step": 7700
    },
    {
      "epoch": 1.7985702755678543,
      "grad_norm": 0.36755600571632385,
      "learning_rate": 8.332267348896706e-06,
      "loss": 0.3187,
      "step": 7800
    },
    {
      "epoch": 1.821630347054076,
      "grad_norm": 0.4019879698753357,
      "learning_rate": 8.172369683402623e-06,
      "loss": 0.3166,
      "step": 7900
    },
    {
      "epoch": 1.8446904185402975,
      "grad_norm": 0.3884052336215973,
      "learning_rate": 8.01247201790854e-06,
      "loss": 0.3123,
      "step": 8000
    },
    {
      "epoch": 1.8446904185402975,
      "eval_loss": 0.3244505524635315,
      "eval_runtime": 737.087,
      "eval_samples_per_second": 10.46,
      "eval_steps_per_second": 2.616,
      "step": 8000
    },
    {
      "epoch": 1.867750490026519,
      "grad_norm": 0.3181561827659607,
      "learning_rate": 7.852574352414455e-06,
      "loss": 0.3147,
      "step": 8100
    },
    {
      "epoch": 1.8908105615127409,
      "grad_norm": 0.378939688205719,
      "learning_rate": 7.692676686920372e-06,
      "loss": 0.3191,
      "step": 8200
    },
    {
      "epoch": 1.9138706329989623,
      "grad_norm": 0.36621081829071045,
      "learning_rate": 7.532779021426287e-06,
      "loss": 0.3162,
      "step": 8300
    },
    {
      "epoch": 1.9369307044851838,
      "grad_norm": 0.3785659968852997,
      "learning_rate": 7.372881355932204e-06,
      "loss": 0.3211,
      "step": 8400
    },
    {
      "epoch": 1.9599907759714055,
      "grad_norm": 0.3823019862174988,
      "learning_rate": 7.21298369043812e-06,
      "loss": 0.3226,
      "step": 8500
    },
    {
      "epoch": 1.9599907759714055,
      "eval_loss": 0.3235776126384735,
      "eval_runtime": 737.1949,
      "eval_samples_per_second": 10.459,
      "eval_steps_per_second": 2.615,
      "step": 8500
    },
    {
      "epoch": 1.9830508474576272,
      "grad_norm": 0.41443589329719543,
      "learning_rate": 7.053086024944037e-06,
      "loss": 0.3106,
      "step": 8600
    },
    {
      "epoch": 2.0059956185864176,
      "grad_norm": 0.35263216495513916,
      "learning_rate": 6.8931883594499525e-06,
      "loss": 0.3195,
      "step": 8700
    },
    {
      "epoch": 2.029055690072639,
      "grad_norm": 0.36712804436683655,
      "learning_rate": 6.733290693955869e-06,
      "loss": 0.3178,
      "step": 8800
    },
    {
      "epoch": 2.052115761558861,
      "grad_norm": 0.3915380537509918,
      "learning_rate": 6.5733930284617856e-06,
      "loss": 0.3145,
      "step": 8900
    },
    {
      "epoch": 2.0751758330450825,
      "grad_norm": 0.34999534487724304,
      "learning_rate": 6.413495362967701e-06,
      "loss": 0.3065,
      "step": 9000
    },
    {
      "epoch": 2.0751758330450825,
      "eval_loss": 0.3229920268058777,
      "eval_runtime": 737.1941,
      "eval_samples_per_second": 10.459,
      "eval_steps_per_second": 2.615,
      "step": 9000
    },
    {
      "epoch": 2.098235904531304,
      "grad_norm": 0.3899773955345154,
      "learning_rate": 6.253597697473618e-06,
      "loss": 0.3042,
      "step": 9100
    },
    {
      "epoch": 2.121295976017526,
      "grad_norm": 0.40768322348594666,
      "learning_rate": 6.093700031979534e-06,
      "loss": 0.3174,
      "step": 9200
    },
    {
      "epoch": 2.1443560475037473,
      "grad_norm": 0.3751417398452759,
      "learning_rate": 5.933802366485449e-06,
      "loss": 0.3208,
      "step": 9300
    },
    {
      "epoch": 2.1674161189899688,
      "grad_norm": 0.35594442486763,
      "learning_rate": 5.773904700991366e-06,
      "loss": 0.3175,
      "step": 9400
    },
    {
      "epoch": 2.1904761904761907,
      "grad_norm": 0.4764847159385681,
      "learning_rate": 5.614007035497282e-06,
      "loss": 0.3176,
      "step": 9500
    },
    {
      "epoch": 2.1904761904761907,
      "eval_loss": 0.32269108295440674,
      "eval_runtime": 737.0956,
      "eval_samples_per_second": 10.46,
      "eval_steps_per_second": 2.616,
      "step": 9500
    },
    {
      "epoch": 2.213536261962412,
      "grad_norm": 0.3902468979358673,
      "learning_rate": 5.454109370003199e-06,
      "loss": 0.3122,
      "step": 9600
    },
    {
      "epoch": 2.2365963334486336,
      "grad_norm": 0.4252164959907532,
      "learning_rate": 5.294211704509114e-06,
      "loss": 0.3143,
      "step": 9700
    },
    {
      "epoch": 2.259656404934855,
      "grad_norm": 0.4003901183605194,
      "learning_rate": 5.1343140390150305e-06,
      "loss": 0.3143,
      "step": 9800
    },
    {
      "epoch": 2.282716476421077,
      "grad_norm": 0.4123680889606476,
      "learning_rate": 4.9744163735209475e-06,
      "loss": 0.3144,
      "step": 9900
    },
    {
      "epoch": 2.3057765479072985,
      "grad_norm": 0.3703133165836334,
      "learning_rate": 4.814518708026863e-06,
      "loss": 0.312,
      "step": 10000
    },
    {
      "epoch": 2.3057765479072985,
      "eval_loss": 0.32199400663375854,
      "eval_runtime": 737.1414,
      "eval_samples_per_second": 10.459,
      "eval_steps_per_second": 2.616,
      "step": 10000
    },
    {
      "epoch": 2.32883661939352,
      "grad_norm": 0.3432294428348541,
      "learning_rate": 4.654621042532779e-06,
      "loss": 0.3022,
      "step": 10100
    },
    {
      "epoch": 2.351896690879742,
      "grad_norm": 0.4035130739212036,
      "learning_rate": 4.494723377038696e-06,
      "loss": 0.3168,
      "step": 10200
    },
    {
      "epoch": 2.3749567623659633,
      "grad_norm": 0.38163334131240845,
      "learning_rate": 4.334825711544612e-06,
      "loss": 0.3159,
      "step": 10300
    },
    {
      "epoch": 2.398016833852185,
      "grad_norm": 0.38019102811813354,
      "learning_rate": 4.174928046050528e-06,
      "loss": 0.3174,
      "step": 10400
    },
    {
      "epoch": 2.4210769053384067,
      "grad_norm": 0.38883987069129944,
      "learning_rate": 4.015030380556444e-06,
      "loss": 0.3176,
      "step": 10500
    },
    {
      "epoch": 2.4210769053384067,
      "eval_loss": 0.32156580686569214,
      "eval_runtime": 737.3514,
      "eval_samples_per_second": 10.456,
      "eval_steps_per_second": 2.615,
      "step": 10500
    },
    {
      "epoch": 2.444136976824628,
      "grad_norm": 0.4371565580368042,
      "learning_rate": 3.85513271506236e-06,
      "loss": 0.3194,
      "step": 10600
    },
    {
      "epoch": 2.4671970483108496,
      "grad_norm": 0.4400343596935272,
      "learning_rate": 3.6952350495682763e-06,
      "loss": 0.3109,
      "step": 10700
    },
    {
      "epoch": 2.4902571197970715,
      "grad_norm": 0.4483470320701599,
      "learning_rate": 3.535337384074193e-06,
      "loss": 0.3118,
      "step": 10800
    },
    {
      "epoch": 2.513317191283293,
      "grad_norm": 0.4231202304363251,
      "learning_rate": 3.375439718580109e-06,
      "loss": 0.3176,
      "step": 10900
    },
    {
      "epoch": 2.5363772627695145,
      "grad_norm": 0.42204490303993225,
      "learning_rate": 3.2155420530860254e-06,
      "loss": 0.3203,
      "step": 11000
    },
    {
      "epoch": 2.5363772627695145,
      "eval_loss": 0.3212316930294037,
      "eval_runtime": 737.0853,
      "eval_samples_per_second": 10.46,
      "eval_steps_per_second": 2.616,
      "step": 11000
    },
    {
      "epoch": 2.559437334255736,
      "grad_norm": 0.4198283553123474,
      "learning_rate": 3.055644387591941e-06,
      "loss": 0.3097,
      "step": 11100
    },
    {
      "epoch": 2.582497405741958,
      "grad_norm": 0.4086187779903412,
      "learning_rate": 2.8957467220978577e-06,
      "loss": 0.3119,
      "step": 11200
    },
    {
      "epoch": 2.6055574772281793,
      "grad_norm": 0.42340385913848877,
      "learning_rate": 2.7358490566037738e-06,
      "loss": 0.3136,
      "step": 11300
    },
    {
      "epoch": 2.6286175487144012,
      "grad_norm": 0.39125367999076843,
      "learning_rate": 2.57595139110969e-06,
      "loss": 0.3226,
      "step": 11400
    },
    {
      "epoch": 2.6516776202006227,
      "grad_norm": 0.41420140862464905,
      "learning_rate": 2.416053725615606e-06,
      "loss": 0.3104,
      "step": 11500
    },
    {
      "epoch": 2.6516776202006227,
      "eval_loss": 0.32090938091278076,
      "eval_runtime": 737.3436,
      "eval_samples_per_second": 10.456,
      "eval_steps_per_second": 2.615,
      "step": 11500
    },
    {
      "epoch": 2.674737691686844,
      "grad_norm": 0.48354652523994446,
      "learning_rate": 2.2561560601215225e-06,
      "loss": 0.313,
      "step": 11600
    },
    {
      "epoch": 2.6977977631730656,
      "grad_norm": 0.4600846767425537,
      "learning_rate": 2.0962583946274386e-06,
      "loss": 0.3097,
      "step": 11700
    },
    {
      "epoch": 2.7208578346592875,
      "grad_norm": 0.40246328711509705,
      "learning_rate": 1.9363607291333547e-06,
      "loss": 0.3119,
      "step": 11800
    },
    {
      "epoch": 2.743917906145509,
      "grad_norm": 0.4518693685531616,
      "learning_rate": 1.776463063639271e-06,
      "loss": 0.3161,
      "step": 11900
    },
    {
      "epoch": 2.766977977631731,
      "grad_norm": 0.35881370306015015,
      "learning_rate": 1.6165653981451873e-06,
      "loss": 0.3152,
      "step": 12000
    },
    {
      "epoch": 2.766977977631731,
      "eval_loss": 0.32068943977355957,
      "eval_runtime": 737.1538,
      "eval_samples_per_second": 10.459,
      "eval_steps_per_second": 2.615,
      "step": 12000
    },
    {
      "epoch": 2.7900380491179524,
      "grad_norm": 0.43973836302757263,
      "learning_rate": 1.4566677326511034e-06,
      "loss": 0.3011,
      "step": 12100
    },
    {
      "epoch": 2.813098120604174,
      "grad_norm": 0.4267764985561371,
      "learning_rate": 1.2967700671570195e-06,
      "loss": 0.3102,
      "step": 12200
    },
    {
      "epoch": 2.8361581920903953,
      "grad_norm": 0.43942034244537354,
      "learning_rate": 1.1368724016629359e-06,
      "loss": 0.3095,
      "step": 12300
    },
    {
      "epoch": 2.8592182635766172,
      "grad_norm": 0.3944058418273926,
      "learning_rate": 9.76974736168852e-07,
      "loss": 0.3161,
      "step": 12400
    },
    {
      "epoch": 2.8822783350628387,
      "grad_norm": 0.42120006680488586,
      "learning_rate": 8.170770706747683e-07,
      "loss": 0.3158,
      "step": 12500
    },
    {
      "epoch": 2.8822783350628387,
      "eval_loss": 0.3205292224884033,
      "eval_runtime": 737.0817,
      "eval_samples_per_second": 10.46,
      "eval_steps_per_second": 2.616,
      "step": 12500
    },
    {
      "epoch": 2.90533840654906,
      "grad_norm": 0.45443469285964966,
      "learning_rate": 6.571794051806844e-07,
      "loss": 0.3088,
      "step": 12600
    },
    {
      "epoch": 2.928398478035282,
      "grad_norm": 0.437222421169281,
      "learning_rate": 4.972817396866006e-07,
      "loss": 0.3231,
      "step": 12700
    },
    {
      "epoch": 2.9514585495215035,
      "grad_norm": 0.3485240936279297,
      "learning_rate": 3.3738407419251685e-07,
      "loss": 0.3132,
      "step": 12800
    },
    {
      "epoch": 2.974518621007725,
      "grad_norm": 0.41222137212753296,
      "learning_rate": 1.7748640869843304e-07,
      "loss": 0.3065,
      "step": 12900
    },
    {
      "epoch": 2.9975786924939465,
      "grad_norm": 0.42450493574142456,
      "learning_rate": 1.7588743204349217e-08,
      "loss": 0.3111,
      "step": 13000
    },
    {
      "epoch": 2.9975786924939465,
      "eval_loss": 0.32043060660362244,
      "eval_runtime": 739.6653,
      "eval_samples_per_second": 10.424,
      "eval_steps_per_second": 2.607,
      "step": 13000
    }
  ],
  "logging_steps": 100,
  "max_steps": 13008,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.232289118668718e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
